{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T15:36:50.498487Z",
     "iopub.status.busy": "2025-05-16T15:36:50.497859Z",
     "iopub.status.idle": "2025-05-16T15:36:50.958883Z",
     "shell.execute_reply": "2025-05-16T15:36:50.958174Z",
     "shell.execute_reply.started": "2025-05-16T15:36:50.498463Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/input/validatiioon'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "kagglehub.dataset_download('hlgsagar1234567/vr-go')\n",
    "kagglehub.dataset_download(\"adityaav80/validatiioon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T15:36:51.031970Z",
     "iopub.status.busy": "2025-05-16T15:36:51.031685Z",
     "iopub.status.idle": "2025-05-16T15:36:51.423706Z",
     "shell.execute_reply": "2025-05-16T15:36:51.423002Z",
     "shell.execute_reply.started": "2025-05-16T15:36:51.031948Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>image_path</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61ee2320.jpg</td>\n",
       "      <td>/kaggle/input/vr-go/go/new/images/small/61/61e...</td>\n",
       "      <td>What is the main color of the phone case?</td>\n",
       "      <td>Black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61ee2320.jpg</td>\n",
       "      <td>/kaggle/input/vr-go/go/new/images/small/61/61e...</td>\n",
       "      <td>What is the object depicted on the phone case?</td>\n",
       "      <td>UFO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61ee2320.jpg</td>\n",
       "      <td>/kaggle/input/vr-go/go/new/images/small/61/61e...</td>\n",
       "      <td>Where is the camera lens positioned on the pho...</td>\n",
       "      <td>Top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61ee2320.jpg</td>\n",
       "      <td>/kaggle/input/vr-go/go/new/images/small/61/61e...</td>\n",
       "      <td>How many stars are visible around the UFO on t...</td>\n",
       "      <td>Seven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61ee2320.jpg</td>\n",
       "      <td>/kaggle/input/vr-go/go/new/images/small/61/61e...</td>\n",
       "      <td>What is the phone case covering?</td>\n",
       "      <td>Phone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_id                                         image_path  \\\n",
       "0  61ee2320.jpg  /kaggle/input/vr-go/go/new/images/small/61/61e...   \n",
       "1  61ee2320.jpg  /kaggle/input/vr-go/go/new/images/small/61/61e...   \n",
       "2  61ee2320.jpg  /kaggle/input/vr-go/go/new/images/small/61/61e...   \n",
       "3  61ee2320.jpg  /kaggle/input/vr-go/go/new/images/small/61/61e...   \n",
       "4  61ee2320.jpg  /kaggle/input/vr-go/go/new/images/small/61/61e...   \n",
       "\n",
       "                                            question answer  \n",
       "0          What is the main color of the phone case?  Black  \n",
       "1     What is the object depicted on the phone case?    UFO  \n",
       "2  Where is the camera lens positioned on the pho...    Top  \n",
       "3  How many stars are visible around the UFO on t...  Seven  \n",
       "4                   What is the phone case covering?  Phone  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/kaggle/input/validatiioon/val_red.csv\")\n",
    "print(len(df))\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T15:36:51.425472Z",
     "iopub.status.busy": "2025-05-16T15:36:51.424888Z",
     "iopub.status.idle": "2025-05-16T15:37:59.464040Z",
     "shell.execute_reply": "2025-05-16T15:37:59.463325Z",
     "shell.execute_reply.started": "2025-05-16T15:36:51.425450Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hf_xet in /usr/local/lib/python3.11/dist-packages (1.1.0)\n",
      "Collecting bert_score\n",
      "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from bert_score) (2.6.0+cu124)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from bert_score) (2.2.3)\n",
      "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from bert_score) (4.51.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from bert_score) (1.26.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from bert_score) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.11/dist-packages (from bert_score) (4.67.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from bert_score) (3.7.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from bert_score) (25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert_score) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert_score) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert_score) (2025.2)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->bert_score) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->bert_score) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->bert_score) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->bert_score) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->bert_score) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->bert_score) (2.4.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (4.13.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.127)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.0.0->bert_score)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.0.0->bert_score)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.0.0->bert_score)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.0.0->bert_score)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.0.0->bert_score)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.0.0->bert_score)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.0.0->bert_score)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert_score) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (0.31.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (0.5.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (1.4.8)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (11.1.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (2025.4.26)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert_score) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.0.0->bert_score) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->bert_score) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->bert_score) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->bert_score) (1.3.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->bert_score) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->bert_score) (2024.2.0)\n",
      "Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bert_score\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.10.19\n",
      "    Uninstalling nvidia-curand-cu12-10.3.10.19:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n",
      "    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n",
      "    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\n",
      "Successfully installed bert_score-0.3.13 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
     ]
    }
   ],
   "source": [
    "!pip install hf_xet bert_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T15:37:59.465638Z",
     "iopub.status.busy": "2025-05-16T15:37:59.465343Z",
     "iopub.status.idle": "2025-05-16T15:40:05.108928Z",
     "shell.execute_reply": "2025-05-16T15:40:05.108350Z",
     "shell.execute_reply.started": "2025-05-16T15:37:59.465606Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-16 15:38:07.740503: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747409887.942997      34 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747409888.004027      34 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS done\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/processing_utils.py:1066: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9beddb4bd308473ea55dc06f674e000d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/432 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c35acc1180f45fa94c8603089132df0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/882 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aeacd2d91564f9cb2bebdadfefa456f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4841fa7285e4f0a9a033ea4a6503bc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d092e16949e34cdd96367fe0ac59d061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/3.56M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "834f93987c514ec98164ca9c251e04b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/23.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "648011397c90475698d8d852de67b076",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/548 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58e0ceee70de4c3f8cc0db452fd1f07e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "processor_config.json:   0%|          | 0.00/68.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:4056: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "417f3963aa7d4e89bb2d4eb90be0da12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.03k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0173795cce6d4a0897267bced76f9232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/122k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f2bb19ff46f4d309f7d78e5f478f0cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8191f569a1644f96bdf1888f4017122e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72ef5a7074134166a2a669a090df86b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/10.0G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04da08de77b04cf8a8f3fec54612f4c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faf60aa4188e4afca50a069ba4fe1eca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/141 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25235a326ffe466484d47288ed9a57db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_config.json:   0%|          | 0.00/752 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6f6f22657524e28a5b1f344daf82c13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/42.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoProcessor, BlipForQuestionAnswering\n",
    "from transformers import (\n",
    "    Blip2Processor,\n",
    "    Blip2ForConditionalGeneration,\n",
    "    GenerationConfig\n",
    ")\n",
    "import os\n",
    "HF_TOKEN = \"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\"\n",
    "REPO_ID = \"HLGS/VR_BLIP_FINE_TUNING\"\n",
    "print(\"OS done\\n\")\n",
    "\n",
    "from peft import PeftModel\n",
    "import torch\n",
    "\n",
    "processor = Blip2Processor.from_pretrained(\n",
    "        \"Salesforce/blip2-opt-2.7b\",\n",
    "        trust_remote_code=True,\n",
    "        use_auth_token=HF_TOKEN\n",
    "    )\n",
    "model = Blip2ForConditionalGeneration.from_pretrained(\n",
    "        \"Salesforce/blip2-opt-2.7b\",\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\",\n",
    "        low_cpu_mem_usage=True,\n",
    "        trust_remote_code=True,\n",
    "        use_auth_token=HF_TOKEN\n",
    "    )\n",
    "\n",
    "\n",
    "# Load PEFT finetuned model weights from your checkpoint\n",
    "model = PeftModel.from_pretrained(\n",
    "    model,\n",
    "    \"HLGS/VR_BLIP_FINE_TUNING\",\n",
    "    subfolder=\"epoch-7\",\n",
    "    is_trainable=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T15:40:05.110719Z",
     "iopub.status.busy": "2025-05-16T15:40:05.109965Z",
     "iopub.status.idle": "2025-05-16T15:40:05.132366Z",
     "shell.execute_reply": "2025-05-16T15:40:05.131575Z",
     "shell.execute_reply.started": "2025-05-16T15:40:05.110689Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "new_model = model.to(device)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T15:40:05.134033Z",
     "iopub.status.busy": "2025-05-16T15:40:05.133764Z",
     "iopub.status.idle": "2025-05-16T15:40:05.138904Z",
     "shell.execute_reply": "2025-05-16T15:40:05.138240Z",
     "shell.execute_reply.started": "2025-05-16T15:40:05.134014Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clears cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T15:40:05.139865Z",
     "iopub.status.busy": "2025-05-16T15:40:05.139613Z",
     "iopub.status.idle": "2025-05-16T15:40:08.328061Z",
     "shell.execute_reply": "2025-05-16T15:40:08.326959Z",
     "shell.execute_reply.started": "2025-05-16T15:40:05.139848Z"
    }
   },
   "outputs": [],
   "source": [
    "!rm -rf ~/.cache/huggingface\n",
    "!rm -rf ~/.cache/torch\n",
    "!rm -rf ~/.cache/evaluate\n",
    "!rm -rf ~/.cache/transformers\n",
    "!rm -rf /kaggle/working/*\n",
    "!rm -rf /kaggle/temp/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T16:43:19.279349Z",
     "iopub.status.busy": "2025-05-16T16:43:19.278816Z",
     "iopub.status.idle": "2025-05-16T16:43:46.305977Z",
     "shell.execute_reply": "2025-05-16T16:43:46.305151Z",
     "shell.execute_reply.started": "2025-05-16T16:43:19.279322Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw answer: Question What is the object depicted on the phone case?. Answer: UU\n",
      "Predicted word: uu\n",
      "Raw answer: Question Where is the camera lens positioned on the phone case?. Answer: TopTopTopTopTopTop\n",
      "Predicted word: top\n",
      "Raw answer: Question How many stars are visible around the UFO on the phone case?. Answer: \n",
      "Predicted word: \n",
      "Raw answer: Question What is the phone case covering?. Answer: \n",
      "Predicted word: \n",
      "Raw answer: Question What is the shape of the UFO on the phone case?. Answer: \n",
      "Predicted word: \n",
      "Raw answer: Question What is the material of the phone case likely to be?. Answer: Plasticasticasticasticasticasticasticasticasticasticasticasticasticasticasticasticasticasticastic\n",
      "Predicted word: plasticastic\n",
      "Raw answer: Question What is written at the bottom of the design on the phone case?. Answer: UUUU\n",
      "Predicted word: uuuu\n",
      "Raw answer: Question What is the color of the design on the phone case?. Answer: \n",
      "Predicted word: \n",
      "Raw answer: Question What is the overall scene depicted on the phone case?. Answer: SpaceSpaceSpaceSpaceSpace\n",
      "Predicted word: space\n",
      "Raw answer: Question What is the shape of the phone case?. Answer: angularangularangularangularangularangularangularangularangularangularangularangularangularangularangularangularangularangularangularangular\n",
      "Predicted word: angular\n",
      "Raw answer: Question What is the dominant color of the phone case?. Answer: \n",
      "Predicted word: \n",
      "Raw answer: Question Where is the phone positioned relative to the case?. Answer: \n",
      "Predicted word: \n",
      "Raw answer: Question How many cats are visible on the case?. Answer: \n",
      "Predicted word: \n",
      "Raw answer: Question What is the phone doing?. Answer: \n",
      "Predicted word: \n",
      "Raw answer: Question What is the size comparison between the phone and the case?. Answer: SameSameSameSameSameSameSameSameSameSameSameSameSameSameSameSameSameSameSameSame\n",
      "Predicted word: same\n",
      "Raw answer: Question What is the shape of the camera lens?. Answer: \n",
      "Predicted word: \n",
      "Raw answer: Question What is the emotion conveyed by the image?. Answer: \n",
      "Predicted word: \n",
      "Raw answer: Question What is the material of the phone case?. Answer: \n",
      "Predicted word: \n",
      "Raw answer: Question What is the relation between the phone and the case?. Answer: Adacentacentacentacentacentacentacentacentacentacentacentacentacentacentacentacentacentacentacent\n",
      "Predicted word: adacentacent\n",
      "Download it dude !!!!!!!!!!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from PIL import Image\n",
    "import re\n",
    "import os\n",
    "import transformers\n",
    "from bert_score import score\n",
    "from transformers import logging\n",
    "\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "def clean_text(text):\n",
    "    return re.sub(r'[^a-zA-Z0-9\\s]', '', str(text).lower().strip())\n",
    "\n",
    "def clean_answer(answer_raw):\n",
    "    # 1) Normalize & pull everything after \"Answer:\"\n",
    "    s = answer_raw.lower()\n",
    "    s = re.split(r'answer:\\s*', s, flags=re.IGNORECASE)[-1].strip()\n",
    "    if not s:\n",
    "        return \"\"\n",
    "\n",
    "    # 2) If already short, just return the first word\n",
    "    if len(s) <= 15:\n",
    "        m = re.match(r'[a-z]+', s)\n",
    "        return m.group(0) if m else \"\"\n",
    "\n",
    "    n = len(s)\n",
    "\n",
    "    # 3) Full‑string repeat?\n",
    "    for d in range(1, n//2 + 1):\n",
    "        if n % d == 0 and s == s[:d] * (n // d):\n",
    "            return s[:d][:15]\n",
    "\n",
    "    # 4) Look for the **latest** cut‐point i where s[i:] is itself a perfect repeat\n",
    "    max_i = min(n, 15)\n",
    "    for i in range(max_i, 0, -1):\n",
    "        tail = s[i:]\n",
    "        tlen = len(tail)\n",
    "        # try every block‐size p dividing the tail\n",
    "        for p in range(1, tlen//2 + 1):\n",
    "            if tlen % p == 0 and tail == tail[:p] * (tlen // p):\n",
    "                return s[:i]\n",
    "\n",
    "    # 5) Fallback: first word\n",
    "    m = re.match(r'[a-z]+', s)\n",
    "    return m.group(0) if m else \"\"\n",
    "\n",
    " \n",
    "\n",
    "st,en = 0,1\n",
    "start_row = int(50050/10)*st+1\n",
    "end_row =  int(50050/10)*en\n",
    "output_csv = f\"/kaggle/working/evaluation_{st}_{en}.csv\"\n",
    "\n",
    "baai = SentenceTransformer(\"BAAI/bge-base-en-v1.5\")\n",
    "\n",
    "results = []\n",
    "image_path = None\n",
    "\n",
    "for i in range(start_row, min(end_row, len(df))):\n",
    "    try:\n",
    "\n",
    "        if i % 10 == 0 or image_path is None:\n",
    "            image_path = df.loc[i, \"image_path\"]\n",
    "            image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        question = df.loc[i, \"question\"]\n",
    "        gt = df.loc[i, \"answer\"]\n",
    "\n",
    "        prompt = f\"Question {question}. Answer: \"\n",
    "\n",
    "        inputs = processor(images=image, text=prompt, return_tensors=\"pt\")\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        # Usage inside your code:\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(**inputs)\n",
    "            raw_answer = processor.decode(outputs[0], skip_special_tokens=True)\n",
    "            pred_short = clean_answer(raw_answer)\n",
    "\n",
    "\n",
    "        if device == \"cuda\":\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        \n",
    "        pred_short_clean = clean_text(pred_short)\n",
    "        gt_clean = clean_text(str(gt))\n",
    "\n",
    "        # Compute similarity only if both GT and prediction exist\n",
    "        if pred_short_clean and gt_clean:\n",
    "            emb_short = baai.encode(pred_short_clean, convert_to_tensor=True, show_progress_bar=False)\n",
    "            emb_gt = baai.encode(gt_clean, convert_to_tensor=True, show_progress_bar=False)\n",
    "            sim_short = min(1.0, round(util.cos_sim(emb_short, emb_gt).item(), 3))\n",
    "        else:\n",
    "            sim_short = \"\"\n",
    "        \n",
    "        if pred_short_clean and gt_clean:\n",
    "            P, R, F1 = score([pred_short_clean], [gt_clean], lang=\"en\", verbose=False)\n",
    "            bert_score_f1 = round(F1.item(), 4)\n",
    "            bert_score_precision = round(P.item(), 4)\n",
    "            bert_score_recall = round(R.item(), 4)\n",
    "        else:\n",
    "            bert_score_f1 = \"\"\n",
    "        \n",
    "        # Exact match only if both exist\n",
    "        exact_match = 1 if pred_short_clean and gt_clean and (pred_short_clean == gt_clean) else 0                    \n",
    "\n",
    "        results.append({\n",
    "            \"index\": i,\n",
    "            \"image_path\": image_path,\n",
    "            \"question\": question,\n",
    "            \"answer\": gt,\n",
    "            \"blip2_prediction_short\": pred_short_clean,\n",
    "            \"baai_similarity_short\": sim_short,\n",
    "            \"bert_score_f1\": bert_score_f1,\n",
    "            \"bert_score_precision\":bert_score_precision,\n",
    "            \"bert_score_recall\":bert_score_recall,\n",
    "            \"blip2_exact_match_short\": exact_match\n",
    "        })\n",
    "        \n",
    "        if i%50 == 0:\n",
    "            print(f\"{i} rows complete\")\n",
    "\n",
    "        if (i - start_row + 1) % 1000 == 0:\n",
    "            pd.DataFrame(results).to_csv(output_csv, mode='a', index=False, header=not os.path.exists(output_csv))\n",
    "            print(f\"[SAVED] Up to row {i}\")\n",
    "            results = []\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] at row {i}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Final save\n",
    "if results:\n",
    "    pd.DataFrame(results).to_csv(output_csv, mode='a', index=False, header=not os.path.exists(output_csv))\n",
    "    print(\"Download it dude !!!!!!!!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7392738,
     "sourceId": 11775052,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7399511,
     "sourceId": 11791179,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
